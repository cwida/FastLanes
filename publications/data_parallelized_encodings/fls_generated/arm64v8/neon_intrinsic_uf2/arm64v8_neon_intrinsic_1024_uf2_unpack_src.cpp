#include "fls_gen/unpack/unpack.hpp"
#include "fls_gen/macros.hpp"
#include <arm_neon.h>
namespace generated
{
	namespace unpack::arm64v8
	{
		namespace neon
		{
			static void unpack_0bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), base_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), base_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), base_1);
				}
			}
			static void unpack_1bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 1), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 1), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 3), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 3), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 5), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 5), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 7), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 7), vdupq_n_u8((1ULL << 1) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_2bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_3bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 3) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 3), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 3), vdupq_n_u8((1ULL << 3) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 1) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 1) - 1)) ,2), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 1), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 1), vdupq_n_u8((1ULL << 3) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 3) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 7), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 7), vdupq_n_u8((1ULL << 1) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 256);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 256);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1)) ,1), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 3) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 5), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 5), vdupq_n_u8((1ULL << 3) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_4bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 256);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 256);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 384);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 384);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_5bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 5) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 5) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 5), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 5), vdupq_n_u8((1ULL << 3) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1)) ,3), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 5) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 5) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 7), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 7), vdupq_n_u8((1ULL << 1) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 256);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 256);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1)) ,1), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 384);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 384);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 1) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 1) - 1)) ,4), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 1), vdupq_n_u8((1ULL << 5) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 1), vdupq_n_u8((1ULL << 5) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 512);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 512);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 3) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 3) - 1)) ,2), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 3), vdupq_n_u8((1ULL << 5) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 3), vdupq_n_u8((1ULL << 5) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_6bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 6) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 6) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 256);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 256);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 6) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 6) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 384);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 384);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 6) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 6) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 512);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 512);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 640);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 640);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 6) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 6) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_7bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					tmp_0 = vandq_u8(register_0, vdupq_n_u8((1ULL << 7) - 1));
					tmp_1 = vandq_u8(register_1, vdupq_n_u8((1ULL << 7) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 7), vdupq_n_u8((1ULL << 1) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 7), vdupq_n_u8((1ULL << 1) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 6) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 6) - 1)) ,1), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 6), vdupq_n_u8((1ULL << 2) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 6), vdupq_n_u8((1ULL << 2) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 256);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 256);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 5) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 5) - 1)) ,2), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 5), vdupq_n_u8((1ULL << 3) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 5), vdupq_n_u8((1ULL << 3) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 384);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 384);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 4) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 4) - 1)) ,3), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 4), vdupq_n_u8((1ULL << 4) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 4), vdupq_n_u8((1ULL << 4) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 512);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 512);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 3) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 3) - 1)) ,4), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 3), vdupq_n_u8((1ULL << 5) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 3), vdupq_n_u8((1ULL << 5) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 640);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 640);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 2) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 2) - 1)) ,5), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 2), vdupq_n_u8((1ULL << 6) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 2), vdupq_n_u8((1ULL << 6) - 1));
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 768);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 768);
					tmp_0 = vorrq_u8(vshlq_n_u64(vandq_u8(register_0, vdupq_n_u8((1ULL << 1) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u8(vshlq_n_u64(vandq_u8(register_1, vdupq_n_u8((1ULL << 1) - 1)) ,6), tmp_1);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), tmp_1);
					tmp_0 = vandq_u8(vshrq_n_u8(register_0, 1), vdupq_n_u8((1ULL << 7) - 1));
					tmp_1 = vandq_u8(vshrq_n_u8(register_1, 1), vdupq_n_u8((1ULL << 7) - 1));
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), tmp_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), tmp_1);
				}
			}
			static void unpack_8bw_8ow_128crw_2uf(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint8x16_t register_0;
				[[maybe_unused]] uint8x16_t tmp_0;
				[[maybe_unused]] uint8x16_t register_1;
				[[maybe_unused]] uint8x16_t tmp_1;
				[[maybe_unused]] int8x16_t base_0 = vmovq_n_u8(0ULL);
				[[maybe_unused]] int8x16_t base_1 = vmovq_n_u8(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 0);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 0);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 0), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 0), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 128);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 128);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 1), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 1), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 256);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 256);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 2), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 2), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 384);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 384);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 3), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 3), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 512);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 512);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 4), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 4), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 640);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 640);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 5), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 5), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 768);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 768);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 6), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 6), register_1);
					register_0 = vld1q_u8(in + (0 * 4 * 16) + (i * 16) + 896);
					register_1 = vld1q_u8(in + (1 * 4 * 16) + (i * 16) + 896);
					vst1q_u8(out + (i * 16) + (0 * 4 * 16) + (128 * 7), register_0);
					vst1q_u8(out + (i * 16) + (1 * 4 * 16) + (128 * 7), register_1);
				}
			}
			static void unpack_0bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), base_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), base_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), base_1);
				}
			}
			static void unpack_1bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_2bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_3bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_4bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_5bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,3), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 5) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_6bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_7bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 5) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 5) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,3), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 5) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,5), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 7) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_8bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_9bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 7) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,7), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 5) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,5), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,3), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 5) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 5) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 7) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 7) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 9) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_10bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_11bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 11) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 5) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,5), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,10), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 11) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 7) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 7) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 9) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,9), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 11) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,3), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 11) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 9) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 9) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 7) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,7), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 11) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 640);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 640);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 5) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 5) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 11) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_12bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 640);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 640);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 704);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 704);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_13bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 13) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 13) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1)) ,3), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 7) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 7) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 9) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,9), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,12), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 13) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 13) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 11) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 11) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 5) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,5), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 5) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 5) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 11) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,11), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 13) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 13) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 640);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 640);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 9) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 9) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 7) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 704);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 704);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,7), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 768);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 768);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1)) ,10), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 13) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 13) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_14bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 14) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 14) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,10), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,12), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 14) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 14) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 14) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 14) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 640);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 640);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 704);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 704);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 768);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 768);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,10), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 832);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 832);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,12), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 14) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 14) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_15bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					tmp_0 = vandq_u16(register_0, vdupq_n_u16((1ULL << 15) - 1));
					tmp_1 = vandq_u16(register_1, vdupq_n_u16((1ULL << 15) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 15), vdupq_n_u16((1ULL << 1) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 15), vdupq_n_u16((1ULL << 1) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 14) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 14) - 1)) ,1), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 14), vdupq_n_u16((1ULL << 2) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 14), vdupq_n_u16((1ULL << 2) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 13) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 13) - 1)) ,2), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 13), vdupq_n_u16((1ULL << 3) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 13), vdupq_n_u16((1ULL << 3) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 12) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 12) - 1)) ,3), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 12), vdupq_n_u16((1ULL << 4) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 12), vdupq_n_u16((1ULL << 4) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 11) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 11) - 1)) ,4), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 11), vdupq_n_u16((1ULL << 5) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 11), vdupq_n_u16((1ULL << 5) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 10) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 10) - 1)) ,5), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 10), vdupq_n_u16((1ULL << 6) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 10), vdupq_n_u16((1ULL << 6) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 9) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 9) - 1)) ,6), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 9), vdupq_n_u16((1ULL << 7) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 9), vdupq_n_u16((1ULL << 7) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 8) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 8) - 1)) ,7), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 8), vdupq_n_u16((1ULL << 8) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 8), vdupq_n_u16((1ULL << 8) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 7) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 7) - 1)) ,8), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 7), vdupq_n_u16((1ULL << 9) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 7), vdupq_n_u16((1ULL << 9) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 6) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 6) - 1)) ,9), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 6), vdupq_n_u16((1ULL << 10) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 6), vdupq_n_u16((1ULL << 10) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 640);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 640);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 5) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 5) - 1)) ,10), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 5), vdupq_n_u16((1ULL << 11) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 5), vdupq_n_u16((1ULL << 11) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 704);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 704);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 4) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 4) - 1)) ,11), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 4), vdupq_n_u16((1ULL << 12) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 4), vdupq_n_u16((1ULL << 12) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 768);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 768);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 3) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 3) - 1)) ,12), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 3), vdupq_n_u16((1ULL << 13) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 3), vdupq_n_u16((1ULL << 13) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 832);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 832);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 2) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 2) - 1)) ,13), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 2), vdupq_n_u16((1ULL << 14) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 2), vdupq_n_u16((1ULL << 14) - 1));
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 896);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 896);
					tmp_0 = vorrq_u16(vshlq_n_u64(vandq_u16(register_0, vdupq_n_u16((1ULL << 1) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u16(vshlq_n_u64(vandq_u16(register_1, vdupq_n_u16((1ULL << 1) - 1)) ,14), tmp_1);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), tmp_1);
					tmp_0 = vandq_u16(vshrq_n_u16(register_0, 1), vdupq_n_u16((1ULL << 15) - 1));
					tmp_1 = vandq_u16(vshrq_n_u16(register_1, 1), vdupq_n_u16((1ULL << 15) - 1));
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), tmp_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), tmp_1);
				}
			}
			static void unpack_16bw_16ow_128crw_2uf(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint16x8_t register_0;
				[[maybe_unused]] uint16x8_t tmp_0;
				[[maybe_unused]] uint16x8_t register_1;
				[[maybe_unused]] uint16x8_t tmp_1;
				[[maybe_unused]] int16x8_t base_0 = vmovq_n_u16(0ULL);
				[[maybe_unused]] int16x8_t base_1 = vmovq_n_u16(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 0);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 0);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 0), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 0), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 64);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 64);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 1), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 1), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 128);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 128);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 2), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 2), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 192);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 192);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 3), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 3), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 256);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 256);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 4), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 4), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 320);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 320);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 5), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 5), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 384);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 384);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 6), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 6), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 448);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 448);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 7), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 7), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 512);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 512);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 8), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 8), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 576);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 576);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 9), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 9), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 640);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 640);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 10), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 10), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 704);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 704);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 11), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 11), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 768);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 768);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 12), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 12), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 832);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 832);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 13), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 13), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 896);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 896);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 14), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 14), register_1);
					register_0 = vld1q_u16(in + (0 * 4 * 8) + (i * 8) + 960);
					register_1 = vld1q_u16(in + (1 * 4 * 8) + (i * 8) + 960);
					vst1q_u16(out + (i * 8) + (0 * 4 * 8) + (64 * 15), register_0);
					vst1q_u16(out + (i * 8) + (1 * 4 * 8) + (64 * 15), register_1);
				}
			}
			static void unpack_0bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), base_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), base_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), base_1);
				}
			}
			static void unpack_1bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_2bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_3bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_4bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_5bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_6bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_7bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_8bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_9bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_10bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_11bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_12bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_13bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_14bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_15bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_16bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_17bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_18bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_19bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_20bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_21bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,19), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 21) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_22bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_23bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 21) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,21), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 21) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 21) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,19), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 23) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_24bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_25bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 21) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,21), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 23) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 23) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 23) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,23), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,19), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 21) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 21) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 25) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_26bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_27bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 27) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 25) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,25), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 27) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 23) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,23), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 27) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 21) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 21) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 21) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,21), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,26), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 27) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 23) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 23) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,19), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 27) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 25) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 25) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 832);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 832);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 27) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_28bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 832);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 832);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 864);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 864);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_29bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 29) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 29) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 23) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 23) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 21) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,21), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 27) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,27), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 29) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 29) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 25) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 25) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,19), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 25) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,25), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,28), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 29) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 29) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 27) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 27) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 21) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 21) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 832);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 832);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 23) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 864);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 864);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,23), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 896);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 896);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,26), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 29) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 29) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_30bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 30) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 30) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,26), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,28), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 30) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 30) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 30) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 30) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 832);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 832);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 864);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 864);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 896);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 896);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,26), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 928);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 928);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,28), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 30) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 30) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_31bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					tmp_0 = vandq_u32(register_0, vdupq_n_u32((1ULL << 31) - 1));
					tmp_1 = vandq_u32(register_1, vdupq_n_u32((1ULL << 31) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 31), vdupq_n_u32((1ULL << 1) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 31), vdupq_n_u32((1ULL << 1) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 30) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 30) - 1)) ,1), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 30), vdupq_n_u32((1ULL << 2) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 30), vdupq_n_u32((1ULL << 2) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 29) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 29) - 1)) ,2), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 29), vdupq_n_u32((1ULL << 3) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 29), vdupq_n_u32((1ULL << 3) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 28) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 28) - 1)) ,3), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 28), vdupq_n_u32((1ULL << 4) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 28), vdupq_n_u32((1ULL << 4) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 27) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 27) - 1)) ,4), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 27), vdupq_n_u32((1ULL << 5) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 27), vdupq_n_u32((1ULL << 5) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 26) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 26) - 1)) ,5), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 26), vdupq_n_u32((1ULL << 6) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 26), vdupq_n_u32((1ULL << 6) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 25) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 25) - 1)) ,6), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 25), vdupq_n_u32((1ULL << 7) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 25), vdupq_n_u32((1ULL << 7) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 24) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 24) - 1)) ,7), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 24), vdupq_n_u32((1ULL << 8) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 24), vdupq_n_u32((1ULL << 8) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 23) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 23) - 1)) ,8), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 23), vdupq_n_u32((1ULL << 9) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 23), vdupq_n_u32((1ULL << 9) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 22) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 22) - 1)) ,9), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 22), vdupq_n_u32((1ULL << 10) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 22), vdupq_n_u32((1ULL << 10) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 21) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 21) - 1)) ,10), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 21), vdupq_n_u32((1ULL << 11) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 21), vdupq_n_u32((1ULL << 11) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 20) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 20) - 1)) ,11), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 20), vdupq_n_u32((1ULL << 12) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 20), vdupq_n_u32((1ULL << 12) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 19) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 19) - 1)) ,12), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 19), vdupq_n_u32((1ULL << 13) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 19), vdupq_n_u32((1ULL << 13) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 18) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 18) - 1)) ,13), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 18), vdupq_n_u32((1ULL << 14) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 18), vdupq_n_u32((1ULL << 14) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 17) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 17) - 1)) ,14), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 17), vdupq_n_u32((1ULL << 15) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 17), vdupq_n_u32((1ULL << 15) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 16) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 16) - 1)) ,15), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 16), vdupq_n_u32((1ULL << 16) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 16), vdupq_n_u32((1ULL << 16) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 15) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 15) - 1)) ,16), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 15), vdupq_n_u32((1ULL << 17) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 15), vdupq_n_u32((1ULL << 17) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 14) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 14) - 1)) ,17), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 14), vdupq_n_u32((1ULL << 18) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 14), vdupq_n_u32((1ULL << 18) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 13) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 13) - 1)) ,18), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 13), vdupq_n_u32((1ULL << 19) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 13), vdupq_n_u32((1ULL << 19) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 12) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 12) - 1)) ,19), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 12), vdupq_n_u32((1ULL << 20) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 12), vdupq_n_u32((1ULL << 20) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 11) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 11) - 1)) ,20), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 11), vdupq_n_u32((1ULL << 21) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 11), vdupq_n_u32((1ULL << 21) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 10) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 10) - 1)) ,21), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 10), vdupq_n_u32((1ULL << 22) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 10), vdupq_n_u32((1ULL << 22) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 9) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 9) - 1)) ,22), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 9), vdupq_n_u32((1ULL << 23) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 9), vdupq_n_u32((1ULL << 23) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 8) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 8) - 1)) ,23), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 8), vdupq_n_u32((1ULL << 24) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 8), vdupq_n_u32((1ULL << 24) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 7) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 7) - 1)) ,24), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 7), vdupq_n_u32((1ULL << 25) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 7), vdupq_n_u32((1ULL << 25) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 6) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 6) - 1)) ,25), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 6), vdupq_n_u32((1ULL << 26) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 6), vdupq_n_u32((1ULL << 26) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 832);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 832);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 5) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 5) - 1)) ,26), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 5), vdupq_n_u32((1ULL << 27) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 5), vdupq_n_u32((1ULL << 27) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 864);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 864);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 4) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 4) - 1)) ,27), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 4), vdupq_n_u32((1ULL << 28) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 4), vdupq_n_u32((1ULL << 28) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 896);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 896);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 3) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 3) - 1)) ,28), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 3), vdupq_n_u32((1ULL << 29) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 3), vdupq_n_u32((1ULL << 29) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 928);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 928);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 2) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 2) - 1)) ,29), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 2), vdupq_n_u32((1ULL << 30) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 2), vdupq_n_u32((1ULL << 30) - 1));
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 960);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 960);
					tmp_0 = vorrq_u32(vshlq_n_u64(vandq_u32(register_0, vdupq_n_u32((1ULL << 1) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u32(vshlq_n_u64(vandq_u32(register_1, vdupq_n_u32((1ULL << 1) - 1)) ,30), tmp_1);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), tmp_1);
					tmp_0 = vandq_u32(vshrq_n_u32(register_0, 1), vdupq_n_u32((1ULL << 31) - 1));
					tmp_1 = vandq_u32(vshrq_n_u32(register_1, 1), vdupq_n_u32((1ULL << 31) - 1));
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), tmp_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), tmp_1);
				}
			}
			static void unpack_32bw_32ow_128crw_2uf(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint32x4_t register_0;
				[[maybe_unused]] uint32x4_t tmp_0;
				[[maybe_unused]] uint32x4_t register_1;
				[[maybe_unused]] uint32x4_t tmp_1;
				[[maybe_unused]] int32x4_t base_0 = vmovq_n_u32(0ULL);
				[[maybe_unused]] int32x4_t base_1 = vmovq_n_u32(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 0);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 0);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 0), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 0), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 32);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 32);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 1), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 1), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 64);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 64);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 2), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 2), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 96);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 96);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 3), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 3), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 128);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 128);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 4), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 4), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 160);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 160);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 5), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 5), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 192);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 192);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 6), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 6), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 224);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 224);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 7), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 7), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 256);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 256);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 8), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 8), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 288);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 288);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 9), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 9), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 320);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 320);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 10), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 10), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 352);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 352);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 11), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 11), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 384);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 384);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 12), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 12), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 416);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 416);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 13), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 13), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 448);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 448);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 14), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 14), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 480);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 480);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 15), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 15), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 512);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 512);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 16), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 16), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 544);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 544);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 17), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 17), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 576);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 576);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 18), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 18), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 608);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 608);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 19), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 19), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 640);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 640);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 20), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 20), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 672);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 672);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 21), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 21), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 704);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 704);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 22), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 22), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 736);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 736);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 23), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 23), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 768);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 768);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 24), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 24), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 800);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 800);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 25), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 25), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 832);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 832);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 26), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 26), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 864);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 864);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 27), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 27), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 896);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 896);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 28), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 28), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 928);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 928);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 29), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 29), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 960);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 960);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 30), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 30), register_1);
					register_0 = vld1q_u32(in + (0 * 4 * 4) + (i * 4) + 992);
					register_1 = vld1q_u32(in + (1 * 4 * 4) + (i * 4) + 992);
					vst1q_u32(out + (i * 4) + (0 * 4 * 4) + (32 * 31), register_0);
					vst1q_u32(out + (i * 4) + (1 * 4 * 4) + (32 * 31), register_1);
				}
			}
			static void unpack_0bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), base_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), base_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), base_1);
				}
			}
			static void unpack_1bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_2bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_3bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_4bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_5bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_6bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_7bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_8bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_9bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_10bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_11bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_12bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_13bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_14bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_15bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_16bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_17bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_18bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_19bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_20bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_21bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_22bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_23bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_24bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_25bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_26bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_27bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_28bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_29bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_30bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_31bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_32bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_33bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_34bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_35bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_36bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_37bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_38bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_39bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_40bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_41bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_42bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_43bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_44bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_45bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_46bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_47bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_48bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_49bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_50bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_51bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_52bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_53bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,51), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,51), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 53) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_54bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_55bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 53) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,53), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,53), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,51), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,51), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 53) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 53) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 55) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_56bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_57bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 55) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,55), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,55), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 53) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 53) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 53) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,53), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,53), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 55) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 55) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,51), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,51), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 57) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_58bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_59bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 59) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 55) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,55), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,55), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 59) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 53) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 53) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,51), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,51), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 59) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 57) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 57) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 57) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,57), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,57), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 59) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 53) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,53), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,53), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,58), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,58), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 59) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 55) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 55) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 928);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 928);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 59) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_60bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 928);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 928);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 944);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 944);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_61bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 61) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 61) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 55) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 55) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,51), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,51), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 57) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,57), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,57), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,60), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,60), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 61) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 61) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 59) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 59) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 53) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 53) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 53) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,53), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,53), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 59) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,59), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,59), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 61) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 61) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 57) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 57) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 928);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 928);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 55) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 944);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 944);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,55), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,55), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 960);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 960);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,58), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,58), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 61) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 61) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_62bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 62) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 62) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,58), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,58), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,60), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,60), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 62) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 62) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 62) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 62) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 928);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 928);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 944);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 944);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 960);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 960);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,58), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,58), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 976);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 976);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,60), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,60), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 62) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 62) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_63bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					tmp_0 = vandq_u64(register_0, vdupq_n_u64((1ULL << 63) - 1));
					tmp_1 = vandq_u64(register_1, vdupq_n_u64((1ULL << 63) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 63), vdupq_n_u64((1ULL << 1) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 63), vdupq_n_u64((1ULL << 1) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 62) - 1)) ,1), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 62) - 1)) ,1), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 62), vdupq_n_u64((1ULL << 2) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 62), vdupq_n_u64((1ULL << 2) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 61) - 1)) ,2), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 61) - 1)) ,2), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 61), vdupq_n_u64((1ULL << 3) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 61), vdupq_n_u64((1ULL << 3) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 60) - 1)) ,3), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 60) - 1)) ,3), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 60), vdupq_n_u64((1ULL << 4) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 60), vdupq_n_u64((1ULL << 4) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 59) - 1)) ,4), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 59) - 1)) ,4), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 59), vdupq_n_u64((1ULL << 5) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 59), vdupq_n_u64((1ULL << 5) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 58) - 1)) ,5), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 58) - 1)) ,5), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 58), vdupq_n_u64((1ULL << 6) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 58), vdupq_n_u64((1ULL << 6) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 57) - 1)) ,6), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 57) - 1)) ,6), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 57), vdupq_n_u64((1ULL << 7) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 57), vdupq_n_u64((1ULL << 7) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 56) - 1)) ,7), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 56) - 1)) ,7), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 56), vdupq_n_u64((1ULL << 8) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 56), vdupq_n_u64((1ULL << 8) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 55) - 1)) ,8), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 55) - 1)) ,8), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 55), vdupq_n_u64((1ULL << 9) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 55), vdupq_n_u64((1ULL << 9) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 54) - 1)) ,9), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 54) - 1)) ,9), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 54), vdupq_n_u64((1ULL << 10) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 54), vdupq_n_u64((1ULL << 10) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 53) - 1)) ,10), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 53) - 1)) ,10), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 53), vdupq_n_u64((1ULL << 11) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 53), vdupq_n_u64((1ULL << 11) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 52) - 1)) ,11), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 52) - 1)) ,11), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 52), vdupq_n_u64((1ULL << 12) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 52), vdupq_n_u64((1ULL << 12) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 51) - 1)) ,12), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 51) - 1)) ,12), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 51), vdupq_n_u64((1ULL << 13) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 51), vdupq_n_u64((1ULL << 13) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 50) - 1)) ,13), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 50) - 1)) ,13), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 50), vdupq_n_u64((1ULL << 14) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 50), vdupq_n_u64((1ULL << 14) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 49) - 1)) ,14), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 49) - 1)) ,14), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 49), vdupq_n_u64((1ULL << 15) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 49), vdupq_n_u64((1ULL << 15) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 48) - 1)) ,15), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 48) - 1)) ,15), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 48), vdupq_n_u64((1ULL << 16) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 48), vdupq_n_u64((1ULL << 16) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 47) - 1)) ,16), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 47) - 1)) ,16), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 47), vdupq_n_u64((1ULL << 17) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 47), vdupq_n_u64((1ULL << 17) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 46) - 1)) ,17), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 46) - 1)) ,17), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 46), vdupq_n_u64((1ULL << 18) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 46), vdupq_n_u64((1ULL << 18) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 45) - 1)) ,18), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 45) - 1)) ,18), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 45), vdupq_n_u64((1ULL << 19) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 45), vdupq_n_u64((1ULL << 19) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 44) - 1)) ,19), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 44) - 1)) ,19), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 44), vdupq_n_u64((1ULL << 20) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 44), vdupq_n_u64((1ULL << 20) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 43) - 1)) ,20), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 43) - 1)) ,20), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 43), vdupq_n_u64((1ULL << 21) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 43), vdupq_n_u64((1ULL << 21) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 42) - 1)) ,21), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 42) - 1)) ,21), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 42), vdupq_n_u64((1ULL << 22) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 42), vdupq_n_u64((1ULL << 22) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 41) - 1)) ,22), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 41) - 1)) ,22), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 41), vdupq_n_u64((1ULL << 23) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 41), vdupq_n_u64((1ULL << 23) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 40) - 1)) ,23), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 40) - 1)) ,23), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 40), vdupq_n_u64((1ULL << 24) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 40), vdupq_n_u64((1ULL << 24) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 39) - 1)) ,24), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 39) - 1)) ,24), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 39), vdupq_n_u64((1ULL << 25) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 39), vdupq_n_u64((1ULL << 25) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 38) - 1)) ,25), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 38) - 1)) ,25), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 38), vdupq_n_u64((1ULL << 26) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 38), vdupq_n_u64((1ULL << 26) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 37) - 1)) ,26), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 37) - 1)) ,26), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 37), vdupq_n_u64((1ULL << 27) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 37), vdupq_n_u64((1ULL << 27) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 36) - 1)) ,27), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 36) - 1)) ,27), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 36), vdupq_n_u64((1ULL << 28) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 36), vdupq_n_u64((1ULL << 28) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 35) - 1)) ,28), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 35) - 1)) ,28), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 35), vdupq_n_u64((1ULL << 29) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 35), vdupq_n_u64((1ULL << 29) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 34) - 1)) ,29), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 34) - 1)) ,29), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 34), vdupq_n_u64((1ULL << 30) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 34), vdupq_n_u64((1ULL << 30) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 33) - 1)) ,30), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 33) - 1)) ,30), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 33), vdupq_n_u64((1ULL << 31) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 33), vdupq_n_u64((1ULL << 31) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 32) - 1)) ,31), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 32) - 1)) ,31), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 32), vdupq_n_u64((1ULL << 32) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 32), vdupq_n_u64((1ULL << 32) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 31) - 1)) ,32), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 31) - 1)) ,32), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 31), vdupq_n_u64((1ULL << 33) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 31), vdupq_n_u64((1ULL << 33) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 30) - 1)) ,33), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 30) - 1)) ,33), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 30), vdupq_n_u64((1ULL << 34) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 30), vdupq_n_u64((1ULL << 34) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 29) - 1)) ,34), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 29) - 1)) ,34), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 29), vdupq_n_u64((1ULL << 35) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 29), vdupq_n_u64((1ULL << 35) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 28) - 1)) ,35), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 28) - 1)) ,35), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 28), vdupq_n_u64((1ULL << 36) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 28), vdupq_n_u64((1ULL << 36) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 27) - 1)) ,36), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 27) - 1)) ,36), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 27), vdupq_n_u64((1ULL << 37) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 27), vdupq_n_u64((1ULL << 37) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 26) - 1)) ,37), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 26) - 1)) ,37), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 26), vdupq_n_u64((1ULL << 38) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 26), vdupq_n_u64((1ULL << 38) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 25) - 1)) ,38), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 25) - 1)) ,38), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 25), vdupq_n_u64((1ULL << 39) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 25), vdupq_n_u64((1ULL << 39) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 24) - 1)) ,39), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 24) - 1)) ,39), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 24), vdupq_n_u64((1ULL << 40) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 24), vdupq_n_u64((1ULL << 40) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 23) - 1)) ,40), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 23) - 1)) ,40), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 23), vdupq_n_u64((1ULL << 41) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 23), vdupq_n_u64((1ULL << 41) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 22) - 1)) ,41), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 22) - 1)) ,41), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 22), vdupq_n_u64((1ULL << 42) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 22), vdupq_n_u64((1ULL << 42) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 21) - 1)) ,42), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 21) - 1)) ,42), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 21), vdupq_n_u64((1ULL << 43) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 21), vdupq_n_u64((1ULL << 43) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 20) - 1)) ,43), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 20) - 1)) ,43), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 20), vdupq_n_u64((1ULL << 44) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 20), vdupq_n_u64((1ULL << 44) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 19) - 1)) ,44), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 19) - 1)) ,44), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 19), vdupq_n_u64((1ULL << 45) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 19), vdupq_n_u64((1ULL << 45) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 18) - 1)) ,45), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 18) - 1)) ,45), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 18), vdupq_n_u64((1ULL << 46) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 18), vdupq_n_u64((1ULL << 46) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 17) - 1)) ,46), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 17) - 1)) ,46), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 17), vdupq_n_u64((1ULL << 47) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 17), vdupq_n_u64((1ULL << 47) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 16) - 1)) ,47), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 16) - 1)) ,47), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 16), vdupq_n_u64((1ULL << 48) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 16), vdupq_n_u64((1ULL << 48) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 15) - 1)) ,48), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 15) - 1)) ,48), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 15), vdupq_n_u64((1ULL << 49) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 15), vdupq_n_u64((1ULL << 49) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 14) - 1)) ,49), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 14) - 1)) ,49), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 14), vdupq_n_u64((1ULL << 50) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 14), vdupq_n_u64((1ULL << 50) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 13) - 1)) ,50), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 13) - 1)) ,50), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 13), vdupq_n_u64((1ULL << 51) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 13), vdupq_n_u64((1ULL << 51) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 12) - 1)) ,51), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 12) - 1)) ,51), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 12), vdupq_n_u64((1ULL << 52) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 12), vdupq_n_u64((1ULL << 52) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 11) - 1)) ,52), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 11) - 1)) ,52), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 11), vdupq_n_u64((1ULL << 53) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 11), vdupq_n_u64((1ULL << 53) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 10) - 1)) ,53), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 10) - 1)) ,53), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 10), vdupq_n_u64((1ULL << 54) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 10), vdupq_n_u64((1ULL << 54) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 9) - 1)) ,54), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 9) - 1)) ,54), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 9), vdupq_n_u64((1ULL << 55) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 9), vdupq_n_u64((1ULL << 55) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 8) - 1)) ,55), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 8) - 1)) ,55), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 8), vdupq_n_u64((1ULL << 56) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 8), vdupq_n_u64((1ULL << 56) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 7) - 1)) ,56), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 7) - 1)) ,56), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 7), vdupq_n_u64((1ULL << 57) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 7), vdupq_n_u64((1ULL << 57) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 6) - 1)) ,57), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 6) - 1)) ,57), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 6), vdupq_n_u64((1ULL << 58) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 6), vdupq_n_u64((1ULL << 58) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 928);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 928);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 5) - 1)) ,58), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 5) - 1)) ,58), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 5), vdupq_n_u64((1ULL << 59) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 5), vdupq_n_u64((1ULL << 59) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 944);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 944);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 4) - 1)) ,59), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 4) - 1)) ,59), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 4), vdupq_n_u64((1ULL << 60) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 4), vdupq_n_u64((1ULL << 60) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 960);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 960);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 3) - 1)) ,60), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 3) - 1)) ,60), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 3), vdupq_n_u64((1ULL << 61) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 3), vdupq_n_u64((1ULL << 61) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 976);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 976);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 2) - 1)) ,61), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 2) - 1)) ,61), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 2), vdupq_n_u64((1ULL << 62) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 2), vdupq_n_u64((1ULL << 62) - 1));
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 992);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 992);
					tmp_0 = vorrq_u64(vshlq_n_u64(vandq_u64(register_0, vdupq_n_u64((1ULL << 1) - 1)) ,62), tmp_0);
					tmp_1 = vorrq_u64(vshlq_n_u64(vandq_u64(register_1, vdupq_n_u64((1ULL << 1) - 1)) ,62), tmp_1);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), tmp_1);
					tmp_0 = vandq_u64(vshrq_n_u64(register_0, 1), vdupq_n_u64((1ULL << 63) - 1));
					tmp_1 = vandq_u64(vshrq_n_u64(register_1, 1), vdupq_n_u64((1ULL << 63) - 1));
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), tmp_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), tmp_1);
				}
			}
			static void unpack_64bw_64ow_128crw_2uf(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p)
			{
				[[maybe_unused]] auto out = (a_out_p);
				[[maybe_unused]] const auto in = (a_in_p);
				[[maybe_unused]] uint64x2_t register_0;
				[[maybe_unused]] uint64x2_t tmp_0;
				[[maybe_unused]] uint64x2_t register_1;
				[[maybe_unused]] uint64x2_t tmp_1;
				[[maybe_unused]] int64x2_t base_0 = vmovq_n_u64(0ULL);
				[[maybe_unused]] int64x2_t base_1 = vmovq_n_u64(0ULL);
				#pragma clang loop unroll(disable)
				for (int i = 0; i < 4; ++i)
				{
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 0);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 0);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 0), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 0), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 16);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 16);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 1), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 1), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 32);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 32);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 2), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 2), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 48);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 48);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 3), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 3), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 64);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 64);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 4), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 4), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 80);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 80);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 5), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 5), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 96);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 96);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 6), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 6), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 112);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 112);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 7), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 7), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 128);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 128);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 8), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 8), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 144);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 144);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 9), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 9), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 160);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 160);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 10), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 10), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 176);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 176);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 11), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 11), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 192);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 192);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 12), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 12), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 208);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 208);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 13), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 13), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 224);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 224);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 14), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 14), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 240);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 240);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 15), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 15), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 256);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 256);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 16), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 16), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 272);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 272);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 17), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 17), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 288);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 288);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 18), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 18), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 304);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 304);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 19), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 19), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 320);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 320);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 20), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 20), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 336);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 336);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 21), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 21), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 352);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 352);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 22), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 22), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 368);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 368);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 23), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 23), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 384);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 384);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 24), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 24), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 400);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 400);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 25), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 25), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 416);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 416);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 26), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 26), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 432);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 432);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 27), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 27), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 448);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 448);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 28), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 28), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 464);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 464);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 29), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 29), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 480);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 480);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 30), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 30), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 496);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 496);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 31), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 31), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 512);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 512);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 32), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 32), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 528);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 528);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 33), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 33), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 544);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 544);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 34), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 34), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 560);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 560);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 35), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 35), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 576);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 576);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 36), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 36), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 592);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 592);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 37), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 37), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 608);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 608);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 38), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 38), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 624);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 624);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 39), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 39), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 640);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 640);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 40), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 40), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 656);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 656);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 41), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 41), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 672);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 672);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 42), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 42), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 688);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 688);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 43), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 43), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 704);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 704);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 44), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 44), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 720);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 720);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 45), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 45), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 736);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 736);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 46), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 46), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 752);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 752);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 47), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 47), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 768);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 768);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 48), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 48), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 784);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 784);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 49), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 49), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 800);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 800);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 50), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 50), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 816);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 816);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 51), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 51), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 832);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 832);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 52), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 52), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 848);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 848);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 53), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 53), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 864);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 864);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 54), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 54), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 880);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 880);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 55), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 55), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 896);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 896);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 56), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 56), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 912);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 912);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 57), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 57), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 928);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 928);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 58), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 58), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 944);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 944);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 59), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 59), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 960);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 960);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 60), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 60), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 976);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 976);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 61), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 61), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 992);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 992);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 62), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 62), register_1);
					register_0 = vld1q_u64(in + (0 * 4 * 2) + (i * 2) + 1008);
					register_1 = vld1q_u64(in + (1 * 4 * 2) + (i * 2) + 1008);
					vst1q_u64(out + (i * 2) + (0 * 4 * 2) + (16 * 63), register_0);
					vst1q_u64(out + (i * 2) + (1 * 4 * 2) + (16 * 63), register_1);
				}
			}
			void unpack(const uint8_t *__restrict a_in_p, uint8_t *__restrict a_out_p, uint8_t bw)
			{
				 switch (bw)
				{
					case 0:
					   unpack_0bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 1:
					   unpack_1bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 2:
					   unpack_2bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 3:
					   unpack_3bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 4:
					   unpack_4bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 5:
					   unpack_5bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 6:
					   unpack_6bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 7:
					   unpack_7bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 8:
					   unpack_8bw_8ow_128crw_2uf(a_in_p, a_out_p);
					   break;
				}
			}
			void unpack(const uint16_t *__restrict a_in_p, uint16_t *__restrict a_out_p, uint8_t bw)
			{
				 switch (bw)
				{
					case 0:
					   unpack_0bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 1:
					   unpack_1bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 2:
					   unpack_2bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 3:
					   unpack_3bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 4:
					   unpack_4bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 5:
					   unpack_5bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 6:
					   unpack_6bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 7:
					   unpack_7bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 8:
					   unpack_8bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 9:
					   unpack_9bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 10:
					   unpack_10bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 11:
					   unpack_11bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 12:
					   unpack_12bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 13:
					   unpack_13bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 14:
					   unpack_14bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 15:
					   unpack_15bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 16:
					   unpack_16bw_16ow_128crw_2uf(a_in_p, a_out_p);
					   break;
				}
			}
			void unpack(const uint32_t *__restrict a_in_p, uint32_t *__restrict a_out_p, uint8_t bw)
			{
				 switch (bw)
				{
					case 0:
					   unpack_0bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 1:
					   unpack_1bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 2:
					   unpack_2bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 3:
					   unpack_3bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 4:
					   unpack_4bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 5:
					   unpack_5bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 6:
					   unpack_6bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 7:
					   unpack_7bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 8:
					   unpack_8bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 9:
					   unpack_9bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 10:
					   unpack_10bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 11:
					   unpack_11bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 12:
					   unpack_12bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 13:
					   unpack_13bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 14:
					   unpack_14bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 15:
					   unpack_15bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 16:
					   unpack_16bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 17:
					   unpack_17bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 18:
					   unpack_18bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 19:
					   unpack_19bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 20:
					   unpack_20bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 21:
					   unpack_21bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 22:
					   unpack_22bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 23:
					   unpack_23bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 24:
					   unpack_24bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 25:
					   unpack_25bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 26:
					   unpack_26bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 27:
					   unpack_27bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 28:
					   unpack_28bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 29:
					   unpack_29bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 30:
					   unpack_30bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 31:
					   unpack_31bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 32:
					   unpack_32bw_32ow_128crw_2uf(a_in_p, a_out_p);
					   break;
				}
			}
			void unpack(const uint64_t *__restrict a_in_p, uint64_t *__restrict a_out_p, uint8_t bw)
			{
				 switch (bw)
				{
					case 0:
					   unpack_0bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 1:
					   unpack_1bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 2:
					   unpack_2bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 3:
					   unpack_3bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 4:
					   unpack_4bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 5:
					   unpack_5bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 6:
					   unpack_6bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 7:
					   unpack_7bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 8:
					   unpack_8bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 9:
					   unpack_9bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 10:
					   unpack_10bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 11:
					   unpack_11bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 12:
					   unpack_12bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 13:
					   unpack_13bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 14:
					   unpack_14bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 15:
					   unpack_15bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 16:
					   unpack_16bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 17:
					   unpack_17bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 18:
					   unpack_18bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 19:
					   unpack_19bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 20:
					   unpack_20bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 21:
					   unpack_21bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 22:
					   unpack_22bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 23:
					   unpack_23bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 24:
					   unpack_24bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 25:
					   unpack_25bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 26:
					   unpack_26bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 27:
					   unpack_27bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 28:
					   unpack_28bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 29:
					   unpack_29bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 30:
					   unpack_30bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 31:
					   unpack_31bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 32:
					   unpack_32bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 33:
					   unpack_33bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 34:
					   unpack_34bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 35:
					   unpack_35bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 36:
					   unpack_36bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 37:
					   unpack_37bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 38:
					   unpack_38bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 39:
					   unpack_39bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 40:
					   unpack_40bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 41:
					   unpack_41bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 42:
					   unpack_42bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 43:
					   unpack_43bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 44:
					   unpack_44bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 45:
					   unpack_45bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 46:
					   unpack_46bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 47:
					   unpack_47bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 48:
					   unpack_48bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 49:
					   unpack_49bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 50:
					   unpack_50bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 51:
					   unpack_51bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 52:
					   unpack_52bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 53:
					   unpack_53bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 54:
					   unpack_54bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 55:
					   unpack_55bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 56:
					   unpack_56bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 57:
					   unpack_57bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 58:
					   unpack_58bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 59:
					   unpack_59bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 60:
					   unpack_60bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 61:
					   unpack_61bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 62:
					   unpack_62bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 63:
					   unpack_63bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
					case 64:
					   unpack_64bw_64ow_128crw_2uf(a_in_p, a_out_p);
					   break;
				}
			}
		}
	}
}
;
